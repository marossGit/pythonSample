# stockLightGBMForeCast.py
# -------------------------
# æœ¬ã‚³ãƒ¼ãƒ‰ã¯ LightGBM ã«ã‚ˆã‚‹ã€Œæ ªä¾¡ãŒä¸Šæ˜‡ã™ã‚‹ç¢ºç‡ã€ã‚’äºˆæ¸¬ã™ã‚‹åˆ†é¡æ©Ÿæ¢°å­¦ç³»ã®ãƒ¢ãƒ‡ãƒ«ã§ã™
# äºˆæ¸¬ç›®æ¨™ã¯ "5ãƒ¶æœˆå¾Œã«æ ªä¾¡ãŒä¸ŠãŒã£ã¦ã„ã‚‹ã‹"

import lightgbm as lgb
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    accuracy_score, roc_auc_score, confusion_matrix,
    classification_report, fbeta_score, precision_score
)
import matplotlib.pyplot as plt
from matplotlib import font_manager as fm
import shap

class stockLightGBMClassifier:
    def __init__(self, baseDeck, futureDeck, nikkeiRate):
        """
        ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ã€‚
        baseDeck: ç¾åœ¨ã®æ ªãƒ‡ãƒ¼ã‚¿ãƒªã‚¹ãƒˆï¼ˆç‰¹å¾´é‡æŠ½å‡ºå…ƒï¼‰
        futureDeck: ç´„5ãƒ¶æœˆå¾Œã®æ ªä¾¡ãƒªã‚¹ãƒˆï¼ˆæ­£è§£ãƒ©ãƒ™ãƒ«ç®—å‡ºç”¨ï¼‰
        nikkeiRate: æœŸé–“ä¸­ã®æ—¥çµŒå¹³å‡ãƒªã‚¿ãƒ¼ãƒ³ï¼ˆæ ªä¾¡å¤‰å‹•è£œæ­£ã«ä½¿ç”¨ï¼‰
        """
        self.stockList = baseDeck["stockList"]
        self.futureStockList = futureDeck["stockList"]
        self.nikkeiRate = nikkeiRate

    def create_training_data(self):
        """
        éŠ˜æŸ„ã”ã¨ã«ç‰¹å¾´é‡ã¨ãƒ©ãƒ™ãƒ«ã‚’ä½œæˆã—ã¦ã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’æ§‹ç¯‰ã€‚
        ç‰¹å¾´é‡ã¯9é …ç›®ã€ãƒ©ãƒ™ãƒ«ã¯ã€Œ5ãƒ¶æœˆå¾Œã«ä¸Šæ˜‡ã—ãŸã‹ã©ã†ã‹ã€
        """
        features = []
        labels = []

        for st in self.stockList:
            df = st.dayData
            if df is None or len(df) < 251:
                continue  # ãƒ‡ãƒ¼ã‚¿ä¸è¶³

            # å¯¾å¿œã™ã‚‹å°†æ¥ãƒ‡ãƒ¼ã‚¿ã‚’æ¤œç´¢
            match = next((f for f in self.futureStockList if f.companyId == st.companyId), None)
            if not match or match.dayData is None or len(match.dayData) < 251:
                continue

            try:
                # ç¾åœ¨çµ‚å€¤ã¨5ãƒ¶æœˆå¾Œçµ‚å€¤ã®å–å¾—
                close_now = df["Close"].iloc[-1]
                close_future = match.dayData["Close"].iloc[-140]

                if close_now <= 1 or np.isnan(close_now) or np.isnan(close_future):
                    continue

                # æ—¥çµŒå¹³å‡å¤‰å‹•ç‡ã§æ­£è¦åŒ–ã—ãŸãƒªã‚¿ãƒ¼ãƒ³è¨ˆç®—
                price_return = (close_future - close_now) / close_now * 100 / self.nikkeiRate
                if abs(price_return) > 500:
                    continue  # ç•°å¸¸å€¤é™¤å¤–

                if st.evalAll < 50:
                    continue  # è©•ä¾¡ãŒä½ã„éŠ˜æŸ„ã¯é™¤å¤–

                # 9ã¤ã®ç‰¹å¾´é‡ã‚’æŠ½å‡º
                row = [
                    st.evalPerform["score"][1],  # è³‡ç”£ã¨è³‡æœ¬
                    st.evalPerform["score"][2],  # å£²ä¸Šã¨åˆ©ç›Š
                    st.evalPerform["score"][3],  # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ãƒ­ãƒ¼
                    st.evalPerform["score"][4],  # ç†è«–æ ªä¾¡ã¨ã®ä¹–é›¢
                    st.evalPerform["score"][5],  # ROEã®è©³ç´°åˆ†æ
                    st.evalPerform["score"][6],  # å››åŠæœŸè©•ä¾¡
                    st.evalChart["score"][5],    # ãƒãƒ£ãƒ¼ãƒˆãƒ™ãƒ¼ã‚¹ã®éå¯¾ç§°ãƒ™ãƒ¼ã‚¿
                    st.evalSupply["score"][1],   # å‡ºæ¥é«˜
                    st.evalSupply["score"][2]    # éœ€çµ¦
                ]

                if any([np.isnan(x) for x in row]):
                    continue

                label = 1 if price_return > 0 else 0  # ä¸Šæ˜‡:1 / éä¸Šæ˜‡:0
                features.append(row)
                labels.append(label)

            except Exception:
                continue  # äºˆæœŸã›ã¬ãƒ‡ãƒ¼ã‚¿ã‚¨ãƒ©ãƒ¼ã¯ã‚¹ã‚­ãƒƒãƒ—

        # DataFrame ã¸å¤‰æ›
        self.X = pd.DataFrame(features, columns=[
            "è³‡ç”£ã¨è³‡æœ¬", "å£²ä¸Šã¨å–¶æ¥­åˆ©ç›Š", "ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ãƒ­ãƒ¼", "ç†è«–æ ªä¾¡", "ROEã®è©³ç´°", "å››åå››åˆ†æ",
            "éå¸¸å€¤ãƒ™ãƒ¼ã‚¿", "å‡ºæ¥é«˜", "éœ€çµ¦"
        ])
        self.y = pd.Series(labels)

    def train_model(self):
        """
        LightGBMåˆ†é¡å™¨ã‚’å­¦ç¿’ã—ã€åŸºæœ¬çš„ãªè©•ä¾¡ã‚¹ã‚³ã‚¢ã¨ç‰¹å¾´é‡é‡è¦åº¦ã‚’è¡¨ç¤ºã€‚
        """
        X_train, X_test, y_train, y_test = train_test_split(
            self.X, self.y, test_size=0.2, random_state=42)

        self.model = lgb.LGBMClassifier(
            objective="binary",
            n_estimators=100,
            random_state=42
        )
        self.model.fit(X_train, y_train)

        preds = self.model.predict(X_test)
        probas = self.model.predict_proba(X_test)[:, 1]

        print("\nâœ… ãƒ¢ãƒ‡ãƒ«è©•ä¾¡")
        print(f"Accuracy: {accuracy_score(y_test, preds):.3f}")
        print(f"AUC: {roc_auc_score(y_test, probas):.3f}")
        print("Confusion Matrix:\n", confusion_matrix(y_test, preds))
        print("\nClassification Report:\n", classification_report(y_test, preds))

        print("\n--- ç‰¹å¾´é‡é‡è¦åº¦ ---")
        for name, score in zip(self.X.columns, self.model.feature_importances_):
            print(f"{name}: {score}")

    def predict_proba(self, x):
        """
        ä»»æ„ã®9ç‰¹å¾´é‡ãƒ™ã‚¯ãƒˆãƒ«ã‚’å…¥åŠ›ã¨ã—ã€
        ã‚¯ãƒ©ã‚¹1ï¼ˆæ ªä¾¡ä¸Šæ˜‡ï¼‰ã®ç¢ºç‡ã‚’è¿”ã™ã€‚
        """
        return self.model.predict_proba([x])[0][1]

    def evaluate_model_performance(self):
        """
        äºˆæ¸¬ç¢ºç‡ã«å¯¾ã—ã¦F0.5ã‚¹ã‚³ã‚¢ã‚’æœ€å¤§åŒ–ã™ã‚‹ã—ãã„å€¤ã‚’æ¢ç´¢ã—ã€
        ãã®è©•ä¾¡ã‚’å¯è¦–åŒ–ï¼ˆã—ãã„å€¤ãƒ—ãƒ­ãƒƒãƒˆãƒ»ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ãƒ»SHAPï¼‰
        """
        if not hasattr(self, "model"):
            print("âŒ ãƒ¢ãƒ‡ãƒ«ãŒè¨“ç·´ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚train_model() ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
            return

        X_test = self.X
        y_true = self.y
        y_prob = self.model.predict_proba(X_test)[:, 1]

        # ã—ãã„å€¤ã‚’0.3ã€œ0.9ã¾ã§è©¦ã—ã€F0.5ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
        thresholds = np.linspace(0.3, 0.9, 100)
        best_thresh, best_f05 = 0.5, 0
        f05_scores = []

        for t in thresholds:
            preds = [1 if p >= t else 0 for p in y_prob]
            f05 = fbeta_score(y_true, preds, beta=0.5)
            f05_scores.append(f05)
            if f05 > best_f05:
                best_f05 = f05
                best_thresh = t

        print(f"\nğŸ¯ æœ€é©ãªã—ãã„å€¤ (F0.5æœ€å¤§): {best_thresh:.2f} (F0.5: {best_f05:.3f})")
        final_preds = [1 if p >= best_thresh else 0 for p in y_prob]
        final_precision = precision_score(y_true, final_preds)
        print(f"Precision: {final_precision:.3f}")

        # --- ã—ãã„å€¤ vs F0.5ã‚¹ã‚³ã‚¢ ãƒ—ãƒ­ãƒƒãƒˆ ---
        plt.figure(figsize=(8, 5))
        plt.plot(thresholds, f05_scores, label='F0.5 Score')
        plt.axvline(x=best_thresh, color='r', linestyle='--', label=f'Threshold = {best_thresh:.2f}')
        plt.xlabel('Threshold')
        plt.ylabel('F0.5 Score')
        plt.title('F0.5 Score vs Threshold')
        plt.legend()
        plt.grid(True)
        plt.tight_layout()
        plt.show()

        # --- ã‚¯ãƒ©ã‚¹åˆ¥äºˆæ¸¬ç¢ºç‡ã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ  ---
        y_prob_0 = [p for p, t in zip(y_prob, y_true) if t == 0]
        y_prob_1 = [p for p, t in zip(y_prob, y_true) if t == 1]

        plt.figure(figsize=(8, 5))
        plt.hist(y_prob_0, bins=20, alpha=0.6, label='Class 0 (Down)', color='orange')
        plt.hist(y_prob_1, bins=20, alpha=0.6, label='Class 1 (Up)', color='skyblue')
        plt.axvline(x=best_thresh, color='red', linestyle='--', label=f'Threshold = {best_thresh:.2f}')
        plt.xlabel('Predicted Probability')
        plt.ylabel('Count')
        plt.title('Prediction Probability Distribution by True Class')
        plt.legend()
        plt.grid(True)
        plt.tight_layout()
        plt.show()

        # --- SHAPå€¤ã«ã‚ˆã‚‹ç‰¹å¾´é‡ã®å¯„ä¸åº¦å¯è¦–åŒ– ---
        explainer = shap.Explainer(self.model.predict_proba, self.X)
        shap_values = explainer(self.X)

        font_path = "C:/Windows/Fonts/meiryo.ttc"  # æ—¥æœ¬èªãƒ©ãƒ™ãƒ«å¯¾å¿œãƒ•ã‚©ãƒ³ãƒˆ
        jp_font = fm.FontProperties(fname=font_path)

        shap.summary_plot(shap_values[:, :, 1], self.X, feature_names=self.X.columns, show=False)
        ax = plt.gca()
        for label in ax.get_yticklabels():
            label.set_fontproperties(jp_font)
            label.set_fontsize(12)
        plt.tight_layout()
        plt.show()
